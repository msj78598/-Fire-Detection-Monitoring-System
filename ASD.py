import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av
import torch
import cv2
import numpy as np

# âœ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLOv5
MODEL_PATH = "best.pt"

# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH, source="github")
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ YOLOv5 Ø¨Ù†Ø¬Ø§Ø­!")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ YOLOv5: {e}")

# âœ… ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Fire Detection Monitoring", page_icon="ğŸ”¥", layout="wide")

# âœ… ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.title("ğŸ”¥ Fire Detection Monitoring System")
st.markdown("<h4 style='text-align: center; color: #FF5733;'>Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø±ÙŠÙ‚</h4>", unsafe_allow_html=True)

# âœ… Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
mode = st.sidebar.radio("ğŸ“Œ Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:", ["ğŸ¥ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©", "ğŸ“‚ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ"])

# âœ… 1ï¸âƒ£ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¹Ø¨Ø± `Streamlit WebRTC`
if mode == "ğŸ¥ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©":
    st.sidebar.warning("âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…ØªØµÙØ­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§.")

    class FireDetectionTransformer(VideoTransformerBase):
        def transform(self, frame):
            img = frame.to_ndarray(format="bgr24")

            # ğŸ”¹ ØªØ´ØºÙŠÙ„ YOLOv5 Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
            results = model(img)

            # ğŸ”¹ Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
            for *xyxy, conf, cls in results.xyxy[0]:
                x1, y1, x2, y2 = map(int, xyxy)
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                cv2.putText(img, "ğŸ”¥ Fire Detected", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            return av.VideoFrame.from_ndarray(img, format="bgr24")

    webrtc_streamer(key="fire-detection", video_transformer_factory=FireDetectionTransformer)

# âœ… 2ï¸âƒ£ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§
elif mode == "ğŸ“‚ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ":
    uploaded_file = st.sidebar.file_uploader("ğŸ“¸ Ù‚Ù… Ø¨Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ", type=["jpg", "png", "jpeg", "mp4"])

    if uploaded_file:
        file_type = uploaded_file.type.split("/")[0]

        if file_type == "image":
            # âœ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            image = Image.open(uploaded_file)
            image_np = np.array(image)

            # ğŸ”¹ ØªØ´ØºÙŠÙ„ YOLOv5 Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
            results = model(image_np)

            # ğŸ”¹ Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
            for *xyxy, conf, cls in results.xyxy[0]:
                x1, y1, x2, y2 = map(int, xyxy)
                cv2.rectangle(image_np, (x1, y1), (x2, y2), (0, 0, 255), 2)

            # âœ… Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.image(image_np, caption="ğŸ” Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©", use_column_width=True)
            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­!")

        elif file_type == "video":
            # âœ… ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ­Ù„ÙŠÙ„Ù‡ Ø¥Ø·Ø§Ø± Ø¨Ø¥Ø·Ø§Ø±
            video_path = "uploaded_video.mp4"
            with open(video_path, "wb") as f:
                f.write(uploaded_file.read())

            cap = cv2.VideoCapture(video_path)
            stframe = st.empty()

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # ğŸ”¹ ØªØ´ØºÙŠÙ„ YOLOv5 Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
                results = model(frame)

                # ğŸ”¹ Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
                for *xyxy, conf, cls in results.xyxy[0]:
                    x1, y1, x2, y2 = map(int, xyxy)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)

                # âœ… Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                stframe.image(frame_rgb, caption="ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", use_column_width=True)

            cap.release()
            st.success("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­!")
